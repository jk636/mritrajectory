# %% [markdown]
# # Trajectory Optimization with Trajgen Optimizers
#
# This notebook demonstrates how to use the `TrajectoryOptimizer` to find optimal parameters for a trajectory generator based on a custom cost function. We will use the `generate_drunken_kooshball_trajectory` as an example, aiming to optimize its perturbation parameters to balance k-space coverage against hardware constraints and other desirable properties.

# %%
# General Imports
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D # For 3D plotting
import time # To time optimization

# Trajgen Imports
# Ensure trajgen is installed or PYTHONPATH is set correctly
# For example, if running from the 'examples' directory of the project:
# import sys
# import os
# sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from trajgen.trajectory import Trajectory, COMMON_NUCLEI_GAMMA_HZ_PER_T
from trajgen.generators import generate_drunken_kooshball_trajectory
from trajgen.optimizers import (
    TrajectoryOptimizer,
    calculate_hardware_penalty,
    calculate_gradient_roughness_penalty,
    calculate_pns_proxy_penalty
)

# %% [markdown]
# ## 1. Define Fixed Parameters for the Generator
#
# These are parameters for `generate_drunken_kooshball_trajectory` that we will keep constant during this optimization run. The `TrajectoryOptimizer` requires `dt_seconds` to be in these fixed parameters to correctly instantiate `Trajectory` objects internally. `gamma_Hz_per_T` is also good to include, though `Trajectory` has a default. Other parameters like FOV, resolution, and number of points define the basic characteristics of the trajectory we are trying to optimize.
#
# The `max_grad_Tm_per_m` and `max_slew_Tm_per_s_per_m` here are targets for the *generator's internal smoothing loop*. The cost function defined later can use different (e.g., stricter) limits for evaluation.

# %%
fixed_params_kooshball = {
    'name': "opt_kooshball", # Base name, optimizer will add prefixes/suffixes
    'fov_mm': (180.0, 180.0, 180.0),
    'resolution_mm': (3.0, 3.0, 3.0), # k_max will be ~1/(2*3mm) = ~166.67 rad/m
    'num_points': 512,  # Keep low for faster optimization in this example
    'dt_seconds': 4e-6, # 4 microseconds
    'base_spherical_spiral_turns': 6,
    'gamma_Hz_per_T': COMMON_NUCLEI_GAMMA_HZ_PER_T['1H'],
    'max_grad_Tm_per_m': 0.080, # Optional: Target for generator's internal smoothing (80 mT/m)
    'max_slew_Tm_per_s_per_m': 300.0, # Optional: Target for generator's internal smoothing (300 T/m/s)
    'num_smoothing_iterations': 2, # Generator's internal smoothing iterations
    'smoothing_kernel_size': 3     # Generator's internal smoothing kernel size
    # 'smoothness_emphasis_factor' could also be fixed or optimized
}

# %% [markdown]
# ## 2. Define Parameters to Optimize and Their Bounds
#
# We select which parameters of the `generate_drunken_kooshball_trajectory` function we want the optimizer to tune. For each parameter, we provide a `(min_bound, max_bound)` tuple.

# %%
# Parameters to optimize for generate_drunken_kooshball_trajectory
# Format: 'param_name': (min_bound, max_bound)
optimizable_params_config_kooshball = {
    'perturbation_amplitude_factor': (0.01, 0.3), # e.g., 1% to 30% of heuristic scale
    'density_sigma_factor': (0.1, 0.6),         # e.g., relative to k_max
    'smoothness_emphasis_factor': (0.0, 1.0)    # Optimize the balance between randomness and smoothness
}

# %% [markdown]
# ## 3. Define the Custom Cost Function
#
# The cost function is crucial. It takes a `Trajectory` object (generated with a set of parameters) and returns a single floating-point number representing how "bad" that trajectory is. The optimizer will try to minimize this value.
#
# We can combine multiple cost components, each potentially weighted by a `penalty_factor` to adjust its importance.

# %%
def my_custom_cost_function(trajectory: Trajectory) -> float:
    """
    Example cost function for optimizing a Drunken Kooshball trajectory.
    Weights can be adjusted based on priorities.
    A lower cost is better.
    """
    cost = 0.0
    current_params = trajectory.metadata.get('optimized_params_values', []) # Get current params for logging if needed

    # 1. Hardware Penalty (encourage staying within stricter limits than generator's targets)
    # These limits are for the *cost function evaluation*.
    hw_grad_limit = 0.070  # 70 mT/m
    hw_slew_limit = 250.0  # 250 T/m/s

    cost_hw_penalty = calculate_hardware_penalty(
        trajectory,
        grad_limit_Tm_per_m=hw_grad_limit,
        slew_limit_Tm_per_s_per_m=hw_slew_limit,
        penalty_factor=200.0 # High penalty for exceeding these
    )
    cost += cost_hw_penalty

    # 2. Gradient Roughness Penalty (proxy for acoustic noise or vibrations)
    cost_roughness = calculate_gradient_roughness_penalty(
        trajectory,
        penalty_factor=5.0 # Moderate weight
    )
    cost += cost_roughness

    # 3. PNS Proxy Penalty (based on max slew rate achieved)
    pns_slew_threshold = 200.0 # T/m/s
    cost_pns = calculate_pns_proxy_penalty(
        trajectory,
        pns_threshold_T_per_s=pns_slew_threshold,
        penalty_factor=50.0 # Moderate penalty
    )
    cost += cost_pns

    # 4. Encourage k-space coverage (penalize if k_max is too small)
    # This is a simple example; more sophisticated coverage metrics could be used.
    k_points_actual = trajectory.kspace_points_rad_per_m
    if k_points_actual.size > 0:
        k_max_achieved = np.max(np.linalg.norm(k_points_actual, axis=0))
    else:
        k_max_achieved = 0.0

    target_k_max = 1.0 / (2 * (np.min(fixed_params_kooshball['resolution_mm']) / 1000.0))

    # Penalize if less than 80% of target k_max is reached
    k_max_penalty = 0.0
    if k_max_achieved < 0.8 * target_k_max:
        k_max_penalty = 100.0 * ((0.8 * target_k_max - k_max_achieved) / target_k_max)**2
        cost += k_max_penalty

    # Optional: Print components for debugging during optimization (can be verbose)
    # print(f"    Cost Breakdown: HW={cost_hw_penalty:.2e}, Roughness={cost_roughness:.2e}, PNS={cost_pns:.2e}, KmaxPen={k_max_penalty:.2e}")
    return cost

# %% [markdown]
# ## 4. Instantiate and Run the Optimizer
#
# Now we create an instance of `TrajectoryOptimizer` and run the optimization.

# %%
optimizer = TrajectoryOptimizer(
    generator_func=generate_drunken_kooshball_trajectory,
    optimizable_params_config=optimizable_params_config_kooshball,
    cost_evaluator_func=my_custom_cost_function,
    fixed_generator_params=fixed_params_kooshball
)

# Define initial guess (optional, optimizer can guess from midpoints of bounds)
# Order must match keys in optimizable_params_config_kooshball:
# 'perturbation_amplitude_factor', 'density_sigma_factor', 'smoothness_emphasis_factor'
initial_guess = [0.1, 0.3, 0.2]

print("Starting trajectory optimization...")
start_time = time.time()

# Using default L-BFGS-B, with fewer iterations for example speed.
# For real use, maxiter might be 50-200 or more.
# Set disp=True in optimizer_options for more detailed output from scipy.optimize.minimize
optimizer_options = {'maxiter': 20, 'disp': False, 'ftol': 1e-7, 'gtol': 1e-6}

best_trajectory, best_cost, optimization_result = optimizer.optimize(
    initial_guess_values=initial_guess,
    optimizer_options=optimizer_options
)

end_time = time.time()
print(f"\nOptimization finished in {end_time - start_time:.2f} seconds.")

if best_trajectory:
    print(f"Best cost found: {best_cost:.6e}")
    optimized_params_dict = best_trajectory.metadata.get('optimized_params', {})
    print("Optimal parameters:")
    for key, value in optimized_params_dict.items():
        print(f"  {key}: {value:.4f}")

    # Plot the optimized trajectory
    fig = plt.figure(figsize=(8, 8))
    ax = fig.add_subplot(111, projection='3d')
    point_stride_plot = max(1, best_trajectory.get_num_points() // 500) # Aim for ~500 points
    best_trajectory.plot_3d(ax=ax, title=f"Optimized Trajectory (Cost: {best_cost:.2e})",
                            point_stride=point_stride_plot, plot_style='-')
    plt.show()

    print("\nActual hardware usage of optimized trajectory:")
    print(f"  Max Gradient: {best_trajectory.get_max_grad_Tm():.4f} T/m")
    print(f"  Max Slew Rate: {best_trajectory.get_max_slew_Tm_per_s():.2f} T/m/s")
    print(f"  Achieved k_max: {np.max(np.linalg.norm(best_trajectory.kspace_points_rad_per_m, axis=0)):.2f} rad/m")
else:
    print("Optimization did not yield a best trajectory.")

# For more details on the optimization process:
# print("\nFull optimization result object:")
# print(optimization_result)

# %% [markdown]
# ## 5. Discussion and Interpretation
#
# -   **Best Cost**: The `best_cost` value indicates the minimum value found by the optimizer for your `my_custom_cost_function`. A lower value is generally better.
# -   **Optimal Parameters**: The `optimized_params` dictionary in `best_trajectory.metadata` shows the parameter values that yielded this best cost. These are the suggested parameters for your `generate_drunken_kooshball_trajectory` function based on the defined cost function and optimization run.
# -   **Cost Function Weights**: The relative `penalty_factor` values used in `my_custom_cost_function` are critical. If, for example, the hardware penalty is too low, the optimizer might find trajectories that are "good" in other aspects but violate hardware limits. These weights often need empirical tuning based on the specific application and desired trade-offs.
# -   **Optimization Method and Iterations**:
    -   The `L-BFGS-B` method is a common choice for bound-constrained optimization. Other methods available in `scipy.optimize.minimize` (like 'SLSQP', 'TNC') could also be tried and might yield different results or performance.
    -   The `maxiter` in `optimizer_options` was kept low (20) for this example to run quickly. For real applications, increasing this (e.g., to 100, 200, or more) would allow the optimizer more attempts to find a better solution.
    -   The `ftol` and `gtol` parameters control the tolerance for termination. Smaller values mean stricter convergence criteria.
# -   **Initial Guess**: Providing a good `initial_guess_values` can sometimes speed up convergence or help find a better local minimum, though the optimizer can also start from the midpoint of bounds.
# -   **Reproducibility**: Optimization results can sometimes vary slightly between runs or depend on the initial guess, especially for non-convex problems.
# -   **`optimization_result` Object**: The third item returned by `optimizer.optimize()` is the full result object from `scipy.optimize.minimize`. This object contains more detailed information, such as the reason for termination, number of function evaluations, Jacobian/Hessian information (if computed by the method), etc. This can be useful for advanced analysis of the optimization process.
#
# This example provides a starting point. Real-world trajectory optimization often involves more complex cost functions, potentially considering image quality metrics from simulations, scanner-specific constraints, or other performance indicators.

# %%
# Example of how to access more details from the optimization_result
if 'optimization_result' in locals() and optimization_result:
    print("\n--- Detailed Optimization Result ---")
    print(f"Success: {optimization_result.success}")
    print(f"Status Message: {optimization_result.message}")
    print(f"Number of iterations: {optimization_result.nit}")
    print(f"Number of objective function evaluations: {optimization_result.nfev}")
    print(f"Number of Jacobian evaluations (if applicable): {optimization_result.njev}")
    print(f"Final gradient norm (if applicable): {optimization_result.jac if hasattr(optimization_result, 'jac') else 'N/A'}")

```
